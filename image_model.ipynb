{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "# CNN Building Tools below-these lines are causing problems in the code for some reason\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "# from images.ipynb import load_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "df = pd.read_csv(\"HAM10000_metadata.csv\")\n",
    "\n",
    "lesion_type_dict = {\n",
    "    \"nv\": \"Melanocytic nevi\",\n",
    "    \"mel\": \"Melanoma\",\n",
    "    \"bkl\": \"Benign keratosis-like lesions\",\n",
    "    \"akiec\": \"Actinic keratoses\",\n",
    "    \"vasc\": \"Vascular lesions\",\n",
    "    \"df\": \"Dermatofibroma\",\n",
    "    \"bcc\": \"Basal Cell Carcinoma\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dx']\n"
     ]
    }
   ],
   "source": [
    "# features and target variables for train test split\n",
    "# features = df[[\"dx_type\", \"age\", \"sex\", \"localization\", \"img\"]]\n",
    "features = np.load(\"images.npy\")\n",
    "target = df[[\"dx\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.get_dummies(target, columns=[\"dx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test data split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     features, target, test_size=0.20, random_state=42\n",
    "# )\n",
    "\n",
    "# validation and train data split\n",
    "# x_train, x_validate, y_train, y_validate = train_test_split(\n",
    "#     x_train, y_train, test_size=0.1, random_state=42\n",
    "# )\n",
    "\n",
    "x_train = features[:7000]\n",
    "x_validate = features[7000:8000]\n",
    "x_test = features[8000:]\n",
    "\n",
    "y_train = target[:7000]\n",
    "y_validate = target[7000:8000]\n",
    "y_test = target[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of CNN Building\n",
    "input_shape = (450, 650, 3)\n",
    "num_classes = 7\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 450, 650, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 450, 650, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 225, 325, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 225, 325, 32)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 225, 325, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 225, 325, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 112, 162, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 112, 162, 64)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1161216)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 8128519   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8194143 (31.26 MB)\n",
      "Trainable params: 8194143 (31.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Adding layers to the model\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        32,\n",
    "        kernel_size=(3, 3),\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "        input_shape=input_shape,\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"Same\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"Same\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"Same\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 450, 650, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code adds artificial data, to be used after first draft of model is complete\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         zoom_range = 0.1, # Randomly zoom image \n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=False,  # randomly flip images\n",
    "#         vertical_flip=False)  # randomly flip image\n",
    "\n",
    "# datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 100\n",
    "history = model.fit(x_train,y_train, batch_size=batch_size, epochs = epochs, validation_data = (x_validate,y_validate), verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size, callbacks=[learning_rate_reduction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

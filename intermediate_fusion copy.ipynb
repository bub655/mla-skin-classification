{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /Users/anavbo/anaconda3/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/anavbo/anaconda3/lib/python3.11/site-packages (from pydot) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%brew` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydot\n",
    "%brew install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# CNN Building Tools below-these lines are causing problems in the code for some reason\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "\n",
    "# from images.ipynb import load_images\n",
    "from keras.backend import clear_session\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "df = pd.read_csv(\"HAM10000_metadata.csv\")\n",
    "df = df.sort_values(by=\"image_id\")\n",
    "lesion_type_dict = {\n",
    "    \"nv\": \"Melanocytic nevi\",\n",
    "    \"mel\": \"Melanoma\",\n",
    "    \"bkl\": \"Benign keratosis-like lesions\",\n",
    "    \"akiec\": \"Actinic keratoses\",\n",
    "    \"vasc\": \"Vascular lesions\",\n",
    "    \"df\": \"Dermatofibroma\",\n",
    "    \"bcc\": \"Basal Cell Carcinoma\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and target variables for train test split\n",
    "# features = df[[\"dx_type\", \"age\", \"sex\", \"localization\", \"img\"]]\n",
    "features = np.load(\"images.npy\")\n",
    "target = df[[\"dx\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229 132 134]\n",
      "[229 132 134]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"HAM10000_images/ISIC_0024306.jpg\")\n",
    "img = np.array(img.resize((65,45)))\n",
    "print(img[0][0])\n",
    "print(features[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.get_dummies(target, columns=[\"dx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x_train = features[:6000]\n",
    "image_x_val = features[6000:7600]\n",
    "image_x_test = features[7600:]\n",
    "image_y_train = target[:6000]\n",
    "image_y_val = target[6000:7600]\n",
    "image_y_test = target[7600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of CNN Building\n",
    "input_shape = (45, 65, 3)\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 45, 65, 32)        896       \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 45, 65, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 22, 32, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 22, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 22, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 22, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 11, 16, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 11, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 11, 16, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 11, 16, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 5, 8, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 5, 8, 32)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               163968    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 284928 (1.09 MB)\n",
      "Trainable params: 284928 (1.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "model_cnn = Sequential()\n",
    "# Adding layers to the model\n",
    "model_cnn.add(layers.InputLayer(input_shape=input_shape))\n",
    "model_cnn.add(\n",
    "    Conv2D(\n",
    "        32,\n",
    "        kernel_size=(3, 3),\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "    )\n",
    ")\n",
    "\n",
    "model_cnn.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"Same\"))\n",
    "model_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "model_cnn.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"Same\"))\n",
    "model_cnn.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"Same\"))\n",
    "model_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model_cnn.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"Same\"))\n",
    "model_cnn.add(Conv2D(32, (3, 3), activation=\"relu\", padding=\"Same\"))\n",
    "model_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "model_cnn.add(Flatten())\n",
    "# model.add(Dense(128, activation=\"relu\"))\n",
    "model_cnn.add(layers.Dropout(0.25))\n",
    "model_cnn.add(Dense(128))\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[[\"age\", \"localization\", \"sex\"]]\n",
    "text = pd.get_dummies(text, columns=[\"localization\", \"sex\"])\n",
    "text_x_train = np.array(text[:6000])\n",
    "text_x_test = np.array(text[6000:7600])\n",
    "text_x_val = np.array(text[7600:])\n",
    "text_y_train = np.array(target[:6000])\n",
    "text_y_test = np.array(target[6000:7600])\n",
    "text_y_val = np.array(target[7600:])\n",
    "# print(text_x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 200)               4000      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               25728     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29728 (116.12 KB)\n",
      "Trainable params: 29728 (116.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_txt = Sequential()\n",
    "model_txt.add(layers.InputLayer(input_shape=(19,)))\n",
    "model_txt.add(Dense(200, activation=\"linear\"))\n",
    "model_txt.add(Dense(128))\n",
    "model_txt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# text_side = model_txt(text_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([])\n",
    "# for i in range (0, len(image_x_train)):\n",
    "#     x_train[i] = text_train[i] + image_x_train[i]\n",
    "#     x_train = np.array([np.array([text_x_train[i], image_x_train[i]])])\n",
    "\n",
    "# x_train[0] = np.array([text_x_train[0], image_x_train[0]])\n",
    "\n",
    "x_train = [[text_x_train[i], image_x_train[i]] for i in range(0, len(image_x_train))]\n",
    "x_val = [[text_x_val[i], image_x_val[i]] for i in range(0, len(image_x_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "<class 'numpy.ndarray'>\n",
      "45\n",
      "(45, 65, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tmp = x_train[0][1]\n",
    "print(len(x_train))\n",
    "print(type(x_train[0][0]))\n",
    "print(len(tmp))\n",
    "print(tmp.shape)\n",
    "print(type(tmp))\n",
    "# print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img (InputLayer)            [(None, 45, 65, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " txt (InputLayer)            [(None, 19)]                 0         []                            \n",
      "                                                                                                  \n",
      " sequential_18 (Sequential)  (None, 128)                  284928    ['img[0][0]']                 \n",
      "                                                                                                  \n",
      " sequential_19 (Sequential)  (None, 128)                  29728     ['txt[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 256)                  0         ['sequential_18[0][0]',       \n",
      " )                                                                   'sequential_19[0][0]']       \n",
      "                                                                                                  \n",
      " dense_37 (Dense)            (None, 256)                  65792     ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " class (Dense)               (None, 7)                    1799      ['dense_37[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 382247 (1.46 MB)\n",
      "Trainable params: 382247 (1.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_input = layers.Input(shape=input_shape, dtype=tf.int32, name=\"img\")\n",
    "txt_input = layers.Input(shape=(19,), dtype=tf.int32, name=\"txt\")\n",
    "image_side = model_cnn(img_input)\n",
    "text_side = model_txt(txt_input)\n",
    "\n",
    "merged = layers.Concatenate()([image_side, text_side])\n",
    "merged = layers.Dense(256, activation=\"relu\")(merged)\n",
    "output = layers.Dense(7, activation=\"softmax\", name=\"class\")(merged)\n",
    "model = models.Model([img_input, txt_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "# optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0005),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\", patience=3, verbose=1, factor=0.5, min_lr=0.00001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60/60 [==============================] - ETA: 0s - loss: 3.4456 - accuracy: 0.6168WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "60/60 [==============================] - 42s 665ms/step - loss: 3.4456 - accuracy: 0.6168 - lr: 5.0000e-04\n",
      "Epoch 2/5\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9273 - accuracy: 0.6947WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "60/60 [==============================] - 41s 684ms/step - loss: 0.9273 - accuracy: 0.6947 - lr: 5.0000e-04\n",
      "Epoch 3/5\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9227 - accuracy: 0.6947WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "60/60 [==============================] - 41s 684ms/step - loss: 0.9227 - accuracy: 0.6947 - lr: 5.0000e-04\n",
      "Epoch 4/5\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8847 - accuracy: 0.7058WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "60/60 [==============================] - 42s 704ms/step - loss: 0.8847 - accuracy: 0.7058 - lr: 5.0000e-04\n",
      "Epoch 5/5\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8266 - accuracy: 0.7148WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "60/60 [==============================] - 41s 676ms/step - loss: 0.8266 - accuracy: 0.7148 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 100\n",
    "history = model.fit(\n",
    "    [image_x_train, text_x_train],\n",
    "    text_y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=6000 // batch_size,\n",
    "    callbacks=[learning_rate_reduction],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 7)\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(text_y_train.shape)\n",
    "print(len(x_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
